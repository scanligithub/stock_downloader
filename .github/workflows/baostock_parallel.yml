name: ğŸ‚ Baostock å…¨Aè‚¡å†å²æ•°æ®åˆ†å¸ƒå¼ä¸‹è½½ï¼ˆ20 å¹¶å‘ + æ‰‹åŠ¨åˆ—è¡¨ï¼‰

on:
  workflow_dispatch:

jobs:
  download:
    name: ä¸‹è½½åˆ†åŒº ${{ matrix.task_index }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        task_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
      max-parallel: 20

    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies
        run: pip install baostock pandas pyarrow tqdm

      - name: ğŸ“ˆ Run Baostock parallel downloader
        env:
          TASK_INDEX: ${{ matrix.task_index }}
          TASK_COUNT: 20
        run: |
          mkdir -p data
          python scripts/download_baostock_parallel.py

      - name: ğŸ“¤ Upload data partition
        uses: actions/upload-artifact@v4
        with:
          name: data_part_${{ matrix.task_index }}
          path: data/

  merge:
    name: åˆå¹¶æ‰€æœ‰ç»“æœ
    needs: download
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ“¥ Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: all_data

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies
        run: pip install pandas pyarrow tqdm

      - name: ğŸ”„ Merge all results
        run: |
          mkdir -p data
          find all_data -type f -name "*.csv" -exec cp {} data/ \;
          python scripts/merge_results.py

      - name: ğŸ“¦ Compress merged data
        run: zip -r all_data.zip data

      - name: ğŸ“¤ Upload merged dataset
        uses: actions/upload-artifact@v4
        with:
          name: all_data_zip
          path: all_data.zip
