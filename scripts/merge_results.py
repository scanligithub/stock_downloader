# scripts/merge_results.py (é‡æ„ç‰ˆ)

import pandas as pd
import glob
import os
from tqdm import tqdm
import argparse

# (å…³é”®) è¾“å…¥ç›®å½•ç°åœ¨æ˜¯æ‰€æœ‰ artifacts è¢«è§£å‹çš„åœ°æ–¹
INPUT_BASE_DIR = "all_data"
# (å…³é”®) å®šä¹‰ä¸€ä¸ªä¸“é—¨çš„è¾“å‡ºç›®å½•
OUTPUT_DIR = "final_output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

def merge_files(pattern, output_filename):
    """
    é€’å½’æœç´¢ã€åˆå¹¶æ•°æ®åˆ†ç‰‡ï¼Œå¹¶è¿›è¡Œå»é‡ã€‚
    """
    # (å…³é”®) ä½¿ç”¨ recursive=True æ·±åº¦æœç´¢æ‰€æœ‰å­ç›®å½•
    search_pattern = os.path.join(INPUT_BASE_DIR, "**", pattern)
    file_list = glob.glob(search_pattern, recursive=True)

    if not file_list:
        print(f"âš ï¸ æœªæ‰¾åˆ°ä»»ä½•åŒ¹é… '{pattern}' çš„æ–‡ä»¶ï¼Œæ— æ³•åˆå¹¶ã€‚")
        return

    print(f"ğŸ“¦ å…±æ‰¾åˆ° {len(file_list)} ä¸ª '{pattern}' æ–‡ä»¶ï¼Œå¼€å§‹åˆå¹¶...")

    all_dfs = []
    for f in tqdm(file_list, desc=f"æ­£åœ¨è¯»å– {pattern} åˆ†ç‰‡"):
        try:
            df = pd.read_csv(f)
            all_dfs.append(df)
        except Exception as e:
            print(f"\nâš ï¸ è¯»å–æ–‡ä»¶ {f} å¤±è´¥: {e}")

    if not all_dfs:
        print("âš ï¸ æ‰€æœ‰æ–‡ä»¶å‡è¯»å–å¤±è´¥ï¼Œæ— æ³•åˆå¹¶ã€‚")
        return

    print("\n... æ‰€æœ‰åˆ†ç‰‡è¯»å–å®Œæ¯•ï¼Œå¼€å§‹åˆå¹¶ ...")
    merged_df = pd.concat(all_dfs, ignore_index=True)
    
    # (å…³é”®) å¢åŠ å»é‡é€»è¾‘ï¼Œé˜²æ­¢å› é‡å¤è¿è¡Œç­‰åŸå› å¯¼è‡´çš„æ•°æ®é‡å¤
    initial_rows = len(merged_df)
    merged_df.drop_duplicates(inplace=True)
    final_rows = len(merged_df)
    
    if initial_rows > final_rows:
        print(f"â„¹ï¸ å»é‡æ“ä½œç§»é™¤äº† {initial_rows - final_rows} æ¡é‡å¤è®°å½•ã€‚")

    if 'code' in merged_df.columns and 'date' in merged_df.columns:
        merged_df.sort_values(by=['code', 'date'], inplace=True)

    # (å…³é”®) ä¿å­˜ä¸º Parquet æ ¼å¼
    output_path = os.path.join(OUTPUT_DIR, output_filename)
    merged_df.to_parquet(output_path, index=False, compression='zstd')

    print(f"\nâœ… åˆå¹¶å®Œæˆï¼å·²ä¿å­˜ä¸º Parquet æ–‡ä»¶: {output_path}")
    print(f"   - æ€»è®¡è®°å½•æ•°: {len(merged_df)}")
    if 'code' in merged_df.columns:
        print(f"   - æ¶‰åŠè‚¡ç¥¨æ•°: {merged_df['code'].nunique()}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="åˆå¹¶æ•°æ®åˆ†ç‰‡å¹¶ä¿å­˜ä¸º Parquet æ–‡ä»¶ã€‚")
    parser.add_argument('--output', type=str, required=True, help="è¾“å‡ºçš„ Parquet æ–‡ä»¶å")
    args = parser.parse_args()
    
    # æˆ‘ä»¬ç°åœ¨åªåˆå¹¶æ—¥çº¿æ•°æ®
    merge_files("*_kdata.csv", args.output)
    
    # å¦‚æœæœªæ¥æœ‰èµ„é‡‘æµæ•°æ®ï¼Œå¯ä»¥å–æ¶ˆè¿™è¡Œæ³¨é‡Š
    # merge_files("*_moneyflow.csv", "full_moneyflow.parquet")
