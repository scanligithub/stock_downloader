# scripts/collect_and_compress.py (ç±»å‹è½¬æ¢ä¿®æ­£ç‰ˆ)

import pandas as pd
import glob
import os
from tqdm import tqdm
import shutil
import json
from pathlib import Path

# --- é…ç½® ---
INPUT_BASE_DIR = "all_data"
OUTPUT_DIR_SMALL_FILES = "kdata"
FINAL_PARQUET_FILE = "full_kdata.parquet"
QC_REPORT_FILE = "data_quality_report.json"

# ... run_quality_check å‡½æ•°ä¿æŒä¸å˜ ...

def main():
    # ... é˜¶æ®µ 1: æ”¶é›†æ‰€æœ‰å°æ–‡ä»¶ (ä¿æŒä¸å˜) ...

    # --- é˜¶æ®µ 2: åˆ›å»ºä¸€ä¸ªç»è¿‡ä¼˜åŒ–çš„åˆå¹¶å¤§æ–‡ä»¶ ---
    print("\n" + "="*50)
    print("ğŸš€ å¼€å§‹åˆ›å»ºç»è¿‡å‹ç¼©ä¼˜åŒ–çš„åˆå¹¶æ–‡ä»¶...")
    
    all_parquet_files = glob.glob(os.path.join(OUTPUT_DIR_SMALL_FILES, "*.parquet"))
    
    if not all_parquet_files:
        print("âš ï¸ åœ¨æ”¶é›†ç›®å½•ä¸­æœªæ‰¾åˆ° Parquet æ–‡ä»¶ï¼Œæ— æ³•åˆ›å»ºåˆå¹¶æ–‡ä»¶ã€‚")
        return
        
    print(f"ğŸ“¦ æ­£åœ¨è¯»å– {len(all_parquet_files)} ä¸ª Parquet æ–‡ä»¶...")
    all_dfs = [pd.read_parquet(f) for f in tqdm(all_parquet_files, desc="æ­£åœ¨è¯»å–")]
    
    print("... æ­£åœ¨åˆå¹¶æ‰€æœ‰æ•°æ® ...")
    merged_df = pd.concat(all_dfs, ignore_index=True)

    # --- (è¿™æ˜¯å”¯ä¸€çš„ã€å…³é”®çš„ä¿®æ­£) ---
    print("... æ­£åœ¨è¿›è¡Œå¼ºåˆ¶æ•°æ®ç±»å‹è½¬æ¢ ...")
    # å®šä¹‰éœ€è¦è½¬æ¢ä¸ºæ•°å€¼çš„åˆ—
    numeric_cols = [
        'open', 'high', 'low', 'close', 'preclose', 
        'volume', 'amount', 'turn', 'pctChg'
    ]
    # 'isST' åˆ—å¯èƒ½åŒ…å« 0/1 æˆ–ç©ºå­—ç¬¦ä¸²ï¼Œä¹Ÿä¸€å¹¶å¤„ç†
    cols_to_convert = numeric_cols + ['isST']

    for col in cols_to_convert:
        if col in merged_df.columns:
            # ä½¿ç”¨ pd.to_numericï¼Œå¹¶å°†æ— æ³•è½¬æ¢çš„å€¼è®¾ä¸º NaN (ç©ºå€¼)
            merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')

    # å°† 'date' åˆ—è½¬æ¢ä¸º datetime å¯¹è±¡
    if 'date' in merged_df.columns:
        merged_df['date'] = pd.to_datetime(merged_df['date'], errors='coerce')
    
    print("âœ… æ•°æ®ç±»å‹è½¬æ¢å®Œæˆã€‚")
    # ------------------------------------
    
    print(f"... æ­£åœ¨æŒ‰è‚¡ç¥¨ä»£ç  ('code') å¯¹ {len(merged_df)} æ¡è®°å½•è¿›è¡Œæ’åºä»¥ä¼˜åŒ–å‹ç¼©...")
    sorted_df = merged_df.sort_values(by='code', ascending=True).reset_index(drop=True)
    
    output_path = FINAL_PARQUET_FILE
    print(f"... æ­£åœ¨å°†æ’åºåçš„æ•°æ®å†™å…¥æœ€ç»ˆçš„åˆå¹¶æ–‡ä»¶: {output_path} ...")
    
    # ... to_parquet å’Œ run_quality_check çš„è°ƒç”¨ä¿æŒä¸å˜ ...
    try:
        sorted_df.to_parquet(output_path, index=False, compression='zstd', row_group_size=100000)
        print("\nâœ… æœ€ç»ˆåˆå¹¶æ–‡ä»¶åˆ›å»ºæˆåŠŸ (ä½¿ç”¨ zstd å‹ç¼©)ï¼")
    except ImportError:
        # ...
    
    if not sorted_df.empty:
        run_quality_check(sorted_df)
    else:
        print("\nâš ï¸ åˆå¹¶åçš„æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡è´¨é‡æ£€æŸ¥ã€‚")

if __name__ == "__main__":
    main()
