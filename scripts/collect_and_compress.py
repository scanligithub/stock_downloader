# scripts/collect_and_compress.py (æœ€ç»ˆå¥å£®ç‰ˆ)

import pandas as pd
import glob
import os
from tqdm import tqdm
import shutil
import json
from pathlib import Path

# --- é…ç½® ---
INPUT_BASE_DIR = "all_data"
OUTPUT_DIR_SMALL_FILES = "kdata"
FINAL_PARQUET_FILE = "full_kdata.parquet" 
QC_REPORT_FILE = "data_quality_report.json"

# ... run_quality_check å‡½æ•°ä¿æŒä¸å˜ (è¯·ç¡®ä¿æ‚¨ä½¿ç”¨çš„æ˜¯å¸¦æœ‰è¯¥å‡½æ•°çš„ç‰ˆæœ¬) ...
def run_quality_check(df):
    # ... å®Œæ•´çš„è´¨æ£€é€»è¾‘ ...
    pass # è¿™é‡Œçœç•¥ä»¥ä¿æŒç®€æ´ï¼Œè¯·ä½¿ç”¨æ‚¨ä¹‹å‰çš„å®Œæ•´ç‰ˆæœ¬

def main():
    """
    1. æ”¶é›†æ‰€æœ‰åˆ†ç‰‡æ–‡ä»¶ã€‚
    2. åˆå¹¶ã€æ’åºå¹¶ä¿å­˜ä¸ºä¸€ä¸ªä¼˜åŒ–çš„ Parquet å¤§æ–‡ä»¶ã€‚
    3. å¯¹æœ€ç»ˆæ•°æ®è¿›è¡Œè´¨é‡æ£€æŸ¥ã€‚
    """
    
    # --- é˜¶æ®µ 1: æ”¶é›†æ‰€æœ‰å°æ–‡ä»¶ ---
    if os.path.exists(OUTPUT_DIR_SMALL_FILES):
        shutil.rmtree(OUTPUT_DIR_SMALL_FILES)
    os.makedirs(OUTPUT_DIR_SMALL_FILES)

    search_pattern = os.path.join(INPUT_BASE_DIR, "**", "*.parquet")
    file_list = glob.glob(search_pattern, recursive=True)
    
    # --- (è¿™æ˜¯å”¯ä¸€çš„ã€å…³é”®çš„ä¿®æ­£) ---
    if not file_list:
        print("\n" + "="*60)
        print("âŒ è‡´å‘½é”™è¯¯: åœ¨æ‰€æœ‰ä¸‹è½½äº§ç‰©ä¸­ï¼Œæœªæ‰¾åˆ°ä»»ä½• .parquet æ–‡ä»¶ï¼")
        print("   è¿™é€šå¸¸æ„å‘³ç€ä¸Šæ¸¸çš„ 'download' ä½œä¸šè™½ç„¶æ˜¾ç¤ºæˆåŠŸï¼Œä½†å®é™…ä¸Šæ²¡æœ‰ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
        print("   è¯·æ£€æŸ¥ 'download' ä½œä¸šçš„è¯¦ç»†æ—¥å¿—ï¼Œç¡®è®¤æ˜¯å¦æœ‰ 'è‡´å‘½è­¦å‘Š'ã€‚")
        print("="*60)
        exit(1) # æ‰¾ä¸åˆ°æ–‡ä»¶å°±ç›´æ¥æŠ¥é”™é€€å‡ºï¼
    # ------------------------------------

    print(f"ğŸ“¦ å…±æ‰¾åˆ° {len(file_list)} ä¸ªè‚¡ç¥¨çš„ Parquet æ–‡ä»¶ï¼Œå¼€å§‹æ”¶é›†...")
    
    # ... åç»­çš„æ”¶é›†ã€åˆå¹¶ã€æ’åºã€å‹ç¼©ã€è´¨æ£€é€»è¾‘éƒ½ä¿æŒä¸å˜ ...
    for src_path in tqdm(file_list, desc="æ­£åœ¨æ”¶é›†ä¸­"):
        # ...
    # ...
    
    # (ç¡®ä¿ main å‡½æ•°çš„å…¶ä½™éƒ¨åˆ†æ˜¯å®Œæ•´çš„)
    
if __name__ == "__main__":
    main()
    # (é‡è¦) è¯·ç¡®ä¿æ‚¨å°† run_quality_check å‡½æ•°çš„å®Œæ•´å®šä¹‰ä¹Ÿæ”¾åœ¨è¿™ä¸ªæ–‡ä»¶ä¸­
