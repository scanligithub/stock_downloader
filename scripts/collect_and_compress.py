# scripts/collect_and_compress.py

import pandas as pd
import glob
import os
from tqdm import tqdm
import shutil

# --- é…ç½® ---
INPUT_BASE_DIR = "all_data"
OUTPUT_DIR = "kdata" # æœ€ç»ˆè¾“å‡ºçš„æ‰å¹³åŒ–ç›®å½•
FINAL_PARQUET_FILE = "full_kdata.parquet" # æœ€ç»ˆçš„åˆå¹¶å¤§æ–‡ä»¶

def main():
    """
    1. æ”¶é›†æ‰€æœ‰åˆ†ç‰‡æ–‡ä»¶åˆ°ä¸€ä¸ªå¹²å‡€çš„ç›®å½•ã€‚
    2. å°†æ‰€æœ‰æ•°æ®åˆå¹¶ã€æ’åºå¹¶ä¿å­˜ä¸ºä¸€ä¸ªä¼˜åŒ–çš„ Parquet å¤§æ–‡ä»¶ã€‚
    """
    
    # --- é˜¶æ®µ 1: æ”¶é›†æ‰€æœ‰å°æ–‡ä»¶ ---
    if os.path.exists(OUTPUT_DIR):
        shutil.rmtree(OUTPUT_DIR)
    os.makedirs(OUTPUT_DIR)

    search_pattern = os.path.join(INPUT_BASE_DIR, "**", "*.parquet")
    file_list = glob.glob(search_pattern, recursive=True)
    
    if not file_list:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½• Parquet æ•°æ®åˆ†ç‰‡æ–‡ä»¶ã€‚")
        return

    print(f"ğŸ“¦ å…±æ‰¾åˆ° {len(file_list)} ä¸ªè‚¡ç¥¨çš„ Parquet æ–‡ä»¶ï¼Œå¼€å§‹æ”¶é›†...")
    
    for src_path in tqdm(file_list, desc="æ­£åœ¨æ”¶é›†ä¸­"):
        try:
            filename = os.path.basename(src_path)
            dest_path = os.path.join(OUTPUT_DIR, filename)
            shutil.copy2(src_path, dest_path)
        except Exception as e:
            print(f"\nâš ï¸ å¤åˆ¶æ–‡ä»¶ {src_path} å¤±è´¥: {e}")
            
    print(f"\nâœ… å…¨éƒ¨ {len(file_list)} ä¸ªæ–‡ä»¶å·²æˆåŠŸæ”¶é›†åˆ° '{OUTPUT_DIR}' ç›®å½•ä¸­ã€‚")

    # --- é˜¶æ®µ 2: åˆ›å»ºä¸€ä¸ªç»è¿‡ä¼˜åŒ–çš„åˆå¹¶å¤§æ–‡ä»¶ ---
    print("\n" + "="*50)
    print("ğŸš€ å¼€å§‹åˆ›å»ºç»è¿‡å‹ç¼©ä¼˜åŒ–çš„åˆå¹¶æ–‡ä»¶...")
    
    all_parquet_files = glob.glob(os.path.join(OUTPUT_DIR, "*.parquet"))
    
    if not all_parquet_files:
        print("âš ï¸ åœ¨æ”¶é›†ç›®å½•ä¸­æœªæ‰¾åˆ° Parquet æ–‡ä»¶ï¼Œæ— æ³•åˆ›å»ºåˆå¹¶æ–‡ä»¶ã€‚")
        return
        
    print(f"ğŸ“¦ æ­£åœ¨è¯»å– {len(all_parquet_files)} ä¸ª Parquet æ–‡ä»¶...")
    all_dfs = [pd.read_parquet(f) for f in tqdm(all_parquet_files, desc="æ­£åœ¨è¯»å–")]
    
    print("... æ­£åœ¨åˆå¹¶æ‰€æœ‰æ•°æ® ...")
    merged_df = pd.concat(all_dfs, ignore_index=True)
    
    print(f"... æ­£åœ¨æŒ‰è‚¡ç¥¨ä»£ç  ('code') å¯¹ {len(merged_df)} æ¡è®°å½•è¿›è¡Œæ’åºä»¥ä¼˜åŒ–å‹ç¼©...")
    sorted_df = merged_df.sort_values(by='code', ascending=True).reset_index(drop=True)
    
    output_path = FINAL_PARQUET_FILE
    print(f"... æ­£åœ¨å°†æ’åºåçš„æ•°æ®å†™å…¥æœ€ç»ˆçš„åˆå¹¶æ–‡ä»¶: {output_path} ...")
    
    try:
        sorted_df.to_parquet(output_path, index=False, compression='zstd', row_group_size=100000)
        print("\nâœ… æœ€ç»ˆåˆå¹¶æ–‡ä»¶åˆ›å»ºæˆåŠŸ (ä½¿ç”¨ zstd å‹ç¼©)ï¼")
    except ImportError:
        print("\nâš ï¸ è­¦å‘Š: æœªå®‰è£… 'zstandard' åº“ï¼Œå›é€€åˆ° 'snappy' å‹ç¼©ã€‚")
        sorted_df.to_parquet(output_path, index=False, compression='snappy', row_group_size=100000)
        print("\nâœ… æœ€ç»ˆåˆå¹¶æ–‡ä»¶åˆ›å»ºæˆåŠŸ (ä½¿ç”¨ snappy å‹ç¼©)ï¼")

if __name__ == "__main__":
    main()
